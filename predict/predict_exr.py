import streamlit as st
import requests
import pandas as pd
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
from bidi.algorithm import get_display
import arabic_reshaper
from zoneinfo import ZoneInfo
import os
from statsmodels.tsa.stattools import adfuller
from statsmodels.tsa.vector_ar.vecm import coint_johansen
from statsmodels.tsa.statespace.sarimax import SARIMAX
from sklearn.metrics import mean_squared_error
from pytrends.request import TrendReq
import math

# ØªÙ†Ø¸ÛŒÙ… ØµÙØ­Ù‡ Streamlit
st.set_page_config(page_title="Ù†Ø±Ø® Ø¯Ù„Ø§Ø± Ø¢Ø²Ø§Ø¯ Ùˆ Ù†ÛŒÙ…Ø§ Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ÙØ±Ø¯Ø§", layout="wide")
st.markdown("""
---
Â© 2025 Dr. Farhadi. All rights reserved.  
This application was developed by **Dr. Farhadi**, Ph.D. in *Economics (Econometrics)* and *Data Science*.  
All trademarks and intellectual property are protected. â„¢
""")

# ØªØ§Ø¨Ø¹ Ù†Ù…Ø§ÛŒØ´ ØµØ­ÛŒØ­ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ matplotlib
def _(text):
    return get_display(arabic_reshaper.reshape(text))

# ØªØ¹Ø±ÛŒÙ Ø¯ÙˆØ±Ù‡â€ŒÙ‡Ø§ÛŒ Ø±ÛŒØ§Ø³Øª Ø¬Ù…Ù‡ÙˆØ±ÛŒ
presidents = [
    {'name': 'Ø±ÙˆØ­Ø§Ù†ÛŒ', 'start': '2013-08-04', 'end': '2021-08-04', 'color': 'purple'},
    {'name': 'Ø±Ø¦ÛŒØ³ÛŒ', 'start': '2021-08-05', 'end': '2025-08-05', 'color': 'green'},
    {'name': 'Ù¾Ø²Ø´Ú©ÛŒØ§Ù†', 'start': '2025-08-06', 'end': '2033-08-06', 'color': 'turquoise'}
]
for p in presidents:
    p['start'] = datetime.strptime(p['start'], '%Y-%m-%d')
    p['end'] = datetime.strptime(p['end'], '%Y-%m-%d')

# Ú©Ù„Ø§Ø³ Ø§Ø³Ú©Ø±Ù¾ Ù‚ÛŒÙ…Øª Ø§Ø±Ø²
class CurrencyScraper:
    currencies_dict = {
        'USD_Azad': 'price_dollar_rl',
        'USD_Nima': 'nima_buy_usd'
    }
    api_base_url = 'https://api.tgju.org/v1/market/indicator/summary-table-data/'
    @staticmethod
    def clean_price(price_str: str) -> float:
        return float(
            price_str.replace('<span class="high" dir="ltr">', '')
                     .replace('<span class="low" dir="ltr">', '')
                     .replace('</span>', '')
                     .replace(',', '')
        )
    @staticmethod
    def scrape(currency: str) -> pd.DataFrame:
        code = CurrencyScraper.currencies_dict[currency]
        ts = int(datetime.now().timestamp() * 1000)
        url = f"{CurrencyScraper.api_base_url}{code}?period=all&mode=full&ts={ts}"
        r = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
        data = r.json().get('data', [])
        records = []
        for row in data:
            try:
                price = CurrencyScraper.clean_price(row[0])
                date = datetime.strptime(row[6], '%Y/%m/%d')
                records.append({'date': date, 'price': price})
            except:
                continue
        df = pd.DataFrame(records).set_index('date').sort_index()
        return df

# annotation
def annotate_last(ax, x, y, label, color='black'):
    ax.annotate(f'{label}: {y:,.0f}', xy=(x, y), xytext=(10, 10),
                textcoords='offset points', arrowprops=dict(arrowstyle='->', color=color),
                bbox=dict(boxstyle='round', fc='yellow', alpha=0.5))

# ØªØ§Ø¨Ø¹ Ø¯Ø±ÛŒØ§ÙØª Google Trends
@st.cache_data
def fetch_trends(term: str, start: datetime, end: datetime, geo: str = 'IR') -> pd.DataFrame:
    py = TrendReq(hl='fa', tz=+210)
    timeframe = f"{start.strftime('%Y-%m-%d')} {end.strftime('%Y-%m-%d')}"
    py.build_payload([term], timeframe=timeframe, geo=geo)
    df = py.interest_over_time()
    if 'isPartial' in df.columns:
        df = df.drop(columns=['isPartial'])
    df.index = df.index.tz_localize(None)
    return df.rename(columns={term: 'trend'})

# Ø´Ø±ÙˆØ¹ Ø§Ù¾
st.title("Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù†Ø±Ø® Ø¯Ù„Ø§Ø± Ø¢Ø²Ø§Ø¯ Ùˆ Ù†ÛŒÙ…Ø§ Ùˆ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ÙØ±Ø¯Ø§")
with st.spinner("Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§..."):
    scraper = CurrencyScraper()
    df_azad = scraper.scrape('USD_Azad')
    df_nima = scraper.scrape('USD_Nima')
combined = pd.merge(df_azad['price'], df_nima['price'], left_index=True, right_index=True,
                    suffixes=('_azad','_nima'), how='inner')

if combined.empty:
    st.warning("Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯")
else:
    # Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ùˆ Ø¯Ø§Ù†Ù„ÙˆØ¯
    combined['price_gap'] = combined['price_azad'] - combined['price_nima']
    combined['price_gap_ratio'] = combined['price_gap'] / combined['price_azad'] * 100
    st.download_button("ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ CSV", combined.to_csv().encode('utf-8'), "usd_data.csv", "text/csv")

    # Ù†Ù…Ø§ÛŒØ´ Ú†Ø§Ø±Øªâ€ŒÙ‡Ø§
    for title, series_list, colors in [
        (_('Ù†Ø±Ø® Ø¯Ù„Ø§Ø± Ø¢Ø²Ø§Ø¯ Ùˆ Ù†ÛŒÙ…Ø§'), ['price_azad','price_nima'], ['blue','orange']),
        (_('Ø§Ø®ØªÙ„Ø§Ù Ù†Ø±Ø®'), ['price_gap'], ['black']),
        (_('Ù†Ø³Ø¨Øª Ø§Ø®ØªÙ„Ø§Ù (%)'), ['price_gap_ratio'], ['green'])
    ]:
        st.subheader(title)
        fig, ax = plt.subplots(figsize=(12,4))
        for col, col_color in zip(series_list, colors):
            ax.plot(combined.index, combined[col], label=_(col), color=col_color)
        for p in presidents:
            if combined.index.min() <= p['start'] <= combined.index.max():
                ax.axvline(p['start'], color='gray', linestyle='--')
                ax.text(p['start'], ax.get_ylim()[1], _(p['name']), rotation=90,
                         verticalalignment='top', color=p['color'])
        annotate_last(ax, combined.index[-1], combined[series_list[0]].iloc[-1], _(series_list[0]), colors[0])
        ax.legend(); ax.grid(True)
        st.pyplot(fig)

    # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ÙØ±Ø¯Ø§ Ø¨Ø§ Google Trends
    start, end = combined.index.min(), combined.index.max() + timedelta(days=1)
    trends = fetch_trends('Ø¯Ù„Ø§Ø± ÙØ±Ø¯Ø§ÛŒÛŒ', start, end)
    data = combined.join(trends, how='inner').dropna()
    if not data.empty:
        train_y = data['price_azad'].iloc[:-1]
        train_x = data[['trend']].iloc[:-1]
        test_x = data[['trend']].iloc[-1:]
        model = SARIMAX(train_y, exog=train_x, order=(1,1,1), enforce_stationarity=False, enforce_invertibility=False)
        res = model.fit(disp=False)
        pred = res.get_forecast(steps=1, exog=test_x)
        y_pred = pred.predicted_mean.iloc[0]
        y_true = data['price_azad'].iloc[-1]
        rmse = math.sqrt(mean_squared_error([y_true],[y_pred]))
        st.subheader(_('Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù†Ø±Ø® Ø¯Ù„Ø§Ø± ÙØ±Ø¯Ø§'))
        st.write(f"{_('Ù…Ù‚Ø¯Ø§Ø± ÙˆØ§Ù‚Ø¹ÛŒ')}: {y_true:,.0f}")
        st.write(f"{_('Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒØ´Ø¯Ù‡')}: {y_pred:,.0f}")
        st.write(f"{_('RMSE')} : {rmse:.2f}")
        fig_f, ax_f = plt.subplots(figsize=(10,4))
        ax_f.plot(data.index[-30:], data['price_azad'][-30:], label=_('ÙˆØ§Ù‚Ø¹ÛŒ'))
        ax_f.scatter(data.index[-1], y_pred, color='red', label=_('Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ'))
        ax_f.set_title(_('Ù†Ù…ÙˆØ¯Ø§Ø± Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ'))
        ax_f.legend(); ax_f.grid(True)
        st.pyplot(fig_f)
    else:
        st.info(_('Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.'))
